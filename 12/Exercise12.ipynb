{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483a8575",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e135c1c58363c2a93420a8b08bd5c72a",
     "grade": false,
     "grade_id": "cell-ed521fc2ea9083a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise Sheet No. 12\n",
    "\n",
    "---\n",
    "\n",
    "> Machine Learning for Natural Sciences, Summer 2021, Jun.-Prof. Pascal Friederich, pascal.friederich@kit.edu\n",
    "> \n",
    "> Deadline: 18.07.2022, 8 am\n",
    "> \n",
    "> Tutor: navid.haghmoradi@kit.edu  \n",
    "> **Please ask questions in the forum and only contact the Tutor when there are issues with the grading**\n",
    "\n",
    "---\n",
    "**Topic**: This exercise sheet will introduce you to bayes optimization and gaussian processes.\n",
    "\n",
    "**ATTENTION**: Make sure your scipy library is up to date (1.7.0), you can check it running next block,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7354f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e45533001d0fc82a1cf4dd7b1200b3d5",
     "grade": false,
     "grade_id": "cell-30b1cf8f8431ef53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967fca97",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "345c5e5a901837ac5e757dd9ad4e83b9",
     "grade": false,
     "grade_id": "cell-f176d0c9f29a4e71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise we will work on a prototypical implementation of Bayesian Optimization (BayesOpt) based on Gaussian Processes (GP). \n",
    "\n",
    "With BayesOpt we denote a class of machine-learning-based optimization methods based on a sequential strategy and designed for black-box derivative-free global optimization. In the following the pseudocode of BayesOpt framework:\n",
    "\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.0470588); padding:10px 0;font-family:monospace;\">\n",
    "<p><b>BayesOpt</b></p>\n",
    "    <b>for</b> n = 1,2,... <b>do</b><br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;select new $x_{n+1}$ by optimizing acquisition function $\\alpha$<br><br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_{n+1} = argmax_{x} \\alpha(x; \\mathcal{D}_{n})$<br><br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;query objective function to obtain $y_{n+1}$<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;augment data $\\mathcal{D}_{n+1} = {\\mathcal{D}_{n}, (x_{n+1}, y_{n+1})}$<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;update surrogate function<br>\n",
    "    <b>end for</b>\n",
    "</div>\n",
    "\n",
    "The BayesOpt framework has the following key elements:\n",
    "1. the possibility of evaluating the objective function we want to optimize in any given point $x$;\n",
    "2. a surrogate function, a probabilistic model that captures our beliefs about the behavior of the unknown objective function;\n",
    "3. an acquisition function, which is used to select next query point and that has to be cheap to evaluate or approximate.\n",
    "\n",
    "\n",
    "In this notebook we will implement a general BayesOpt framework, GPs as surrogate model and an acquisition function and we will use them to perform hyperparameter optimization on the network you implemented in exercise 6. If you want to know more about BayesOpt a good starting point would be https://ieeexplore.ieee.org/document/7352306.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681952c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2acd9612b03448cceccc80ed28034aa5",
     "grade": false,
     "grade_id": "cell-3f24d00ebb9b6774",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, List, Dict, Union, Optional\n",
    "from matplotlib import cm\n",
    "from scipy.stats import norm\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import cholesky, cho_solve\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gamma, kv\n",
    "\n",
    "Vector = List[float]\n",
    "Matrix = List[List[float]]\n",
    "Coordinates = Union[Tuple[Vector, Vector], List[Vector]] \n",
    "\n",
    "from utils import Kernel, AcquisitionFunc, Regressor, Net, Frame, BayesOpt, Matern52, sobol_sampler, atleast_2d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d57a11",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "319537462243864cd2a672e6bbce5c92",
     "grade": false,
     "grade_id": "cell-1470858626a5e10c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the utils file you can find a simple framework (class Frame) to test the classes and function we will be implementing. \n",
    "\n",
    "Play around with the input parameters to familiarize with the framework (three 1D functions and one 2D functions were implemented, but the class is easily extendable if you want to give it a try)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 1\n",
    "FUNC = 'func_2'\n",
    "NOISE_VAR = 0.05\n",
    "N_SAMPLES = 8\n",
    "\n",
    "test_framework = Frame(dim=DIM, func=FUNC, noise_var = NOISE_VAR)\n",
    "\n",
    "## get_samples\n",
    "observations = test_framework.get_samples(n_samples = N_SAMPLES)\n",
    "print(f'observations is a tuple of numpy arrays of shape: x :{observations[0].shape}, y : {observations[1].shape}')\n",
    "\n",
    "## plot\n",
    "test_framework.plot(samples = observations)\n",
    "\n",
    "### evaluate\n",
    "x = np.random.uniform(test_framework.low, test_framework.up, (1, test_framework.dim))\n",
    "y = test_framework.evaluate(x)\n",
    "print(f'query f() in x = {x.squeeze()} : f(x)={y.item()}')\n",
    "test_framework.plot(samples = (x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3eb2e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd334042e7d1a398c5f2aacc9897900d",
     "grade": false,
     "grade_id": "cell-a2426c2a2958adae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Our Bayesian optimizer will look something like this (take a look at the full code in the utils file):\n",
    "```python\n",
    "class BayesOpt:\n",
    "    def __init__(self, function, surrogate, acquisition, sampler, observations):\n",
    "        self._function = function\n",
    "        self._surrogate = surrogate\n",
    "        self._acquisition = acquisition\n",
    "        self._sampler = sampler\n",
    "        self._observations = observations\n",
    "        \n",
    "    def run(self, stop_criterion):\n",
    "        while not stop_criterion:\n",
    "            self._surrogate.fit(self._observations)\n",
    "            X_next = self.propose_next()\n",
    "            Y_next = self._function.evaluate(X_next)\n",
    "            self._observations.add(X_next, Y_next)\n",
    "        predictions = self._surrogate.predict(self._observations, self)\n",
    "        optimal = np.argmin(predictions)\n",
    "        return self._observations.x[optimal], predictions[optimal]\n",
    "\n",
    "    def propose_next(self):\n",
    "        samples = self._sampler()\n",
    "        vals = self._acquisition(samples)\n",
    "        best = np.argmax(vals)\n",
    "        return samples[best]\n",
    "```\n",
    "\n",
    "So we will need to implement: \n",
    "1. a surrogate model : GP;\n",
    "2. an acquisition function : Expected Improvement (EI); \n",
    "3. a sampler : latin hypercube sampler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f63cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5df36bb0507430fe9f5503283b6f912c",
     "grade": false,
     "grade_id": "cell-8531b7d6a2c98568",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's start from our surrogate model: GPs. \n",
    "\n",
    "In supervised learning we observe tuples $(x_{i}, y_{i})$ and assume that $y_{i}$ is an observation of some unknown function $f(x_{i})$. The optimal approach to make a prediction given new input would be to infer a distribution over functions given the data $p(f|x_{1:n}, y_{1:n})$ and then marginalize:\n",
    "<br><p><center>$p(y|x, x_{1:n}, y_{1:n}) = \\int p(y|x, f)p(f|x_{1:n}, y_{1:n})\\,df$</center></p>\n",
    "\n",
    "A GP defines a prior over functions that can then be converted on a posterior $p(f|x_{1:n}, y_{1:n})$ once some data have been seen. By definition a GP is a collection of random variables, any finite number of which have a joint Gaussian distribution (Rasmussen and Williams, 2006). A GP is completely specified by its mean and covariance functions, where the covariance matrix $\\Sigma$ is assumed as given by $\\Sigma_{ij}=\\kappa(x_{i},x_{j})$, where $\\kappa(\\cdot,\\cdot)$ is a positive definite kernel function. \n",
    "\n",
    "We will denote that the prior on the regression function is a GP by: $f(x)$ ~ $GP(\\mu(x), \\kappa(x, x'))$. It is common to take the mean function to be zero since the GP is flexible enough to model the mean arbitrarily well.\n",
    "\n",
    "(There is a nice introduction to GPs in chapter 15 of Murphy's \"Machine Learning - A Probabilistic Perpective\", or, if you want to know more, I suggest you to take a look at \"Gaussian Processes for Machine Learning\" - Rasmussen and Williams.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc1967",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76e176883ecca7c75a44bd4e9b0ca20f",
     "grade": false,
     "grade_id": "cell-3bddd0cb660a03bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The key element in a GP is the kernel that is used as covariance function. One of the most used kernels is the squared exponential (SE) kernel, also termed Gaussian kernel, defined as:\n",
    "<br><p><center>$\\kappa(x, x') = exp\\,(-\\frac{1}{2}(x-x')^T\\Sigma^{-1}(x-x'))$</center></p><br>\n",
    "(Be careful not to confuse this $\\Sigma$ matrix, the kernel's covariance matrix, with the covariance matrix of the GP we met above).<br>\n",
    "We are going to implement its most straightforward version, the isotropic SE kernel, where the $\\Sigma$ matrix is equal to $\\sigma^{2} \\mathcal{I}$. In this case $\\sigma$ is usually termed 'characteristic length scale', in that it can be roughly interpreted as the distance you have to move in the input space before the function value can change significatively. \n",
    "\n",
    "Complete the code below to compute, given the input vectors $X_{p}$ and $X_{q}$, the covariance matrix and its gradient with respect to the log-transformed length scale ($\\log{\\sigma}$), the second of which we will need later when we want to optimize $\\sigma$ w.r.t. the input data. Here the formulas you should implement:\n",
    "<br><center>$K_{p,q} = \\kappa(x_{p}, x_{q}) = exp\\,(-\\frac{1}{2\\cdot length\\_scale^{2}}(x_{p}-x_{q})^{2})$</center><br>\n",
    "<center>$K\\_grad_{p,q} = \\frac{\\partial K_{p,q}}{\\partial (log\\_length\\_scale)} = \\frac{K_{p,q}\\cdot(x_{p}-x_{q})^{2}}{length\\_scale^{2}}$</center>\n",
    "\n",
    "The gradient is computed with respect to the log-transformed length scale for the same reason why we did the same in our last exercise: if we optimize w.r.t. $\\log{\\sigma}$ we have the guarantee that $\\sigma_{opt}$ is positive.\n",
    "\n",
    "Hints: check 'cdist' function from scipy.\n",
    "\n",
    "If you are curious and want to test other kernels you can easily expand the code, just remember that each implementation must have a __ call__ method and, for each hyperparameter, must store a dictionary of the form: {'name1' : {'value' : value1, 'bounds' : bounds1}} in an attribute named 'hyperparams_name1' (check out also the implementations of Matern kernels in the utils file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c0985b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd4211d78a987e3cfc9721b0c901ee36",
     "grade": false,
     "grade_id": "Kernel",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class SE_isotropic(Kernel):\n",
    "    def __init__(self, length_scale : float = 0.5, length_scale_bounds : Tuple[float] = (1e-2, 1e+1)):\n",
    "        super().__init__()\n",
    "        self.length_scale = length_scale\n",
    "        self.length_scale_bounds = length_scale_bounds\n",
    "\n",
    "    @property\n",
    "    def hyperparam_length_scale(self) -> Dict:\n",
    "        return {'length_scale' : {'value' : self.length_scale, 'bounds' : self.length_scale_bounds}}\n",
    "        \n",
    "    def __call__(self, X_p : Vector, X_q : Optional[Vector] = None, compute_grad : bool = False) -> Matrix:\n",
    "        X_p = atleast_2d(X_p)\n",
    "        if X_q is None:\n",
    "            X_q = X_p\n",
    "        else:\n",
    "            assert compute_grad is False, 'cannot compute gradient if X_q is not None'\n",
    "            X_q = atleast_2d(X_q)\n",
    "            \n",
    "        distance_matrix = None\n",
    "        K = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        if compute_grad:\n",
    "            K_grad = None\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            return K, K_grad\n",
    "        else:\n",
    "            return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ac896",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f47b8fabf4c96109e831ffffc4b5f6d8",
     "grade": true,
     "grade_id": "cell-77c524ca6bce7ede",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Kernel - 1 point\n",
    "\n",
    "np.random.seed(1)\n",
    "kernel = SE_isotropic()\n",
    "test_framework = Frame()\n",
    "\n",
    "X, y = test_framework.get_samples(n_samples = 3)\n",
    "answer = np.array([[1.00000000e+00, 1.32883485e-03, 3.67314625e-06], \n",
    "                   [1.32883485e-03, 1.00000000e+00, 6.03368722e-17],\n",
    "                   [3.67314625e-06, 6.03368722e-17, 1.00000000e+00]])\n",
    "assert np.isclose(answer, kernel(X)).all(), 'ooops...'\n",
    "\n",
    "# similar hidden test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb25df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2456dd6a30e9fad22b87f5fdfef07d02",
     "grade": false,
     "grade_id": "cell-9a6ed307117ec52b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have our kernel we will implement the GP class, but first let's review some theory.\n",
    "\n",
    "NOISY OBSERVATIONS<br>\n",
    "We said that the covariance matrix of the GP is determined by the kernel function $\\kappa(x, x')$, but this was actually a consequence of the fact that we assumed the observations $y_{i}$ to be noise-free. Let's consider instead the case where our $y_{i}$s are noisy observations of the function $f(\\cdot)$ we want to model, i.e. $y_{i} = f(x_{i}) + \\epsilon$, where $\\epsilon$~$\\mathcal{N}(0,\\sigma_{y}^{2})$. In this case the covariance associated with our observations will be $K_{y}=K+\\sigma_{y}^{2}\\mathcal{I}$, where $K$ is determined by a kernel function $\\kappa(x,x')$ as usual. What we are enforcing in practice is that our regressor won't have to exactly interpolate our data, but it will just have to pass as close as possible (depending on the value of $\\sigma_{y}$) to the observations.\n",
    "\n",
    "PREDICTIONS<br>\n",
    "Given a training set $\\mathcal{D}=\\{(x_{i}, y_{i})\\}$ with $i=1,...,N$ and a test set $X_{*}$ we want to predict the objective function $f(X_{*})$, in short $f_{*}$. From the GP definition, and assuming zero-mean for simplicity, follows:\n",
    "<br><center>$\\begin{pmatrix}f_{*} \\\\ y\\end{pmatrix}$ ~ $\\mathcal{N}\\Bigg(\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}, \\begin{pmatrix} K_{**} & K_{*}^T \\\\K_{*} & K_{y}\\end{pmatrix}\\Bigg)$</center><br>\n",
    "where $K_{*}=\\kappa(X, X_{*})$ is $N\\times N_{*}$ and $K_{**}=\\kappa(X_{*}, X_{*})$ is $N_{*}\\times N_{*}$. Then for the theorem about conditional probabilities for Gaussians, the posterior will be:\n",
    "<center>$p(f_{*}|X_{*}, X, y) = \\mathcal{N}(f_{*}|\\mu_{*}, \\Sigma_{*})$</center>\n",
    "<center>$\\mu_{*} = K_{*}^T K_{y}^{-1} y$</center>\n",
    "<center>$\\Sigma_{*} = K_{**} - K_{*}^T K_{y}^{-1} K_{*}$</center>\n",
    "\n",
    "FIT<br>\n",
    "Both kernel parameters and $\\sigma_{y}$ can be optimized with respect to the observed data. This is not strictly necessary for the exercise but for completeness I will say en passant that we will take an empirical Bayes approach and use a continuous optimization method. Check the code or paragraph 15.2.4 of Murphy's textbook if you want to know more.\n",
    "\n",
    "A REMARK ON COMPUTATIONAL STABILITY<br>\n",
    "From the formulas above you have seen that for prediction (and actually for fitting the GP to the data) we need $K_{y}^{-1}$. For numerical stability it is unwise to directly invert the $K$ matrix. More robust approaches would be to compute a Cholesky decomposition of $K$, i.e. $K=LL^{T}$ with $L$ a lower triangular matrix, and than solve $\\alpha = K_{y}^{-1} y = L^{-T}L^{-1}y$ or to solve $\\alpha = K_{y}^{-1} y$ using conjugate gradients (CG). With this second approach modulating the number of iterations of the CG algorithm we can tradeoff the time complexity with the level of approximation on the estimation of $\\alpha$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><b>EXERCISE INSTRUCTIONS</b><br>\n",
    "In the following box you will have to complete the implementation of <b>three</b> functions: \n",
    "1. <b>_compute_K</b>, which returns the matrix $K_{y} = K+\\sigma_{y}^{2}\\mathcal{I}$\n",
    "2. <b>_invert</b>, which takes $K$ as input and inverts it (I suggest to use Cholesky decomposition but it is not mandatory)\n",
    "3. <b>predict</b>, you will have to complete the computation of the posterior mean $\\mu_{*}$ and covariance $\\Sigma_{*}$ as in the equations above.\n",
    "\n",
    "Hints: in case you opted for Cholesky decomposition check scipy 'cho_solve' and 'cholesky' functions (already imported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee27a9c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7044688a6ac45f17a9abe102452c6a9",
     "grade": false,
     "grade_id": "GP",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GP(Regressor):\n",
    "    '''\n",
    "    GP regressor for 1d observations\n",
    "    '''\n",
    "    def __init__(self, kernel : Kernel, noise_sigma : float = 0.1, noise_bounds = (0.01, 0.3)):\n",
    "        self.kernel = kernel\n",
    "        self._noise_sigma = noise_sigma\n",
    "        self._noise_bounds = noise_bounds\n",
    "        self._obs = None\n",
    "        self._obs_scaler = 0\n",
    "        self._K = None\n",
    "        \n",
    "    @property\n",
    "    def noise(self):\n",
    "        return np.log(self._noise_sigma)\n",
    "\n",
    "    @noise.setter\n",
    "    def noise(self, noise_sigma : float):\n",
    "        self._noise_sigma = np.exp(noise_sigma)\n",
    "\n",
    "    @property\n",
    "    def noise_bounds(self):\n",
    "        return tuple(np.log(self._noise_bounds))\n",
    "\n",
    "    def _compute_K(self, obs : Optional[Coordinates] = None):\n",
    "        if obs is not None:\n",
    "            self._obs = obs\n",
    "        self._K = None   # two terms: one is the kernel function, the other the noise associated with the observation process\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _invert(K : Matrix) -> Matrix:\n",
    "        '''\n",
    "        3 options:\n",
    "         - directly invert (this could give errors in other parts of the exercise)\n",
    "         - invert solving system after cholesky decomposition   <----   strongly suggested!\n",
    "         - conjugate gradients on system (time complexity is tunable)\n",
    "        '''\n",
    "        Kinv = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return Kinv\n",
    "\n",
    "    def _nll(self, theta : List[float], compute_grad : bool = True) -> float:\n",
    "        '''\n",
    "        negative log marginal likelihood and gradients\n",
    "        '''\n",
    "        self.kernel.theta = theta[:-1]\n",
    "        self.noise = theta[-1]\n",
    "        if compute_grad:\n",
    "            K, K_grad = self.kernel(self._obs[0], compute_grad=True)\n",
    "        else:\n",
    "            K = self.kernel(self._obs[0])\n",
    "        K += self._noise_sigma**2 * np.eye(K.shape[0])\n",
    "        L = cholesky(K, lower=True)\n",
    "        alpha = cho_solve((L, True), self._obs[1])\n",
    "        l_likelihood = -.5 * self._obs[1].dot(alpha) - np.log(np.diag(L)).sum() - len(K)*.5*np.log(2*np.pi)\n",
    "\n",
    "        if compute_grad:\n",
    "            dummy = np.einsum('i,j->ij', alpha, alpha) - self._invert(K)\n",
    "            # directly compute trace\n",
    "            l_likelihood_grad = [-.5*dummy.ravel().dot(K_grad.T.ravel())]\n",
    "            # add noise\n",
    "            l_likelihood_grad.append(-dummy.ravel().dot((self._noise_sigma*np.eye(K.shape[0])).ravel()))\n",
    "\n",
    "            return -l_likelihood, l_likelihood_grad\n",
    "        else: \n",
    "            return -l_likelihood\n",
    "\n",
    "    def fit(self, obs : Coordinates, optimizer : str = 'L-BFGS-B', n_restarts : int = 40, verbose : bool = False):\n",
    "        '''\n",
    "        only for bounded minimization\n",
    "        '''\n",
    "        assert obs[0].size != 0, 'cannot fit model if no observations are provided'\n",
    "        self._obs_scaler = np.min(obs[1])\n",
    "        self._obs = (obs[0], obs[1] - self._obs_scaler)\n",
    "        def objective_func(theta):\n",
    "            return self._nll(theta)\n",
    "        theta_opt, func_min = [], []\n",
    "        for i in range(n_restarts):\n",
    "            bounds = [tuple(b) for b in self.kernel.bounds]\n",
    "            bounds.append(self.noise_bounds)\n",
    "            if i > 0:\n",
    "                temp = [np.random.uniform(b[0], b[1]) for b in bounds]\n",
    "                gp.kernel.theta = temp[:-1]\n",
    "                gp.noise = temp[-1]\n",
    "\n",
    "            theta = self.kernel.theta\n",
    "            theta = np.append(theta, self.noise)\n",
    "            opt_res = minimize(objective_func, theta, method=optimizer, jac=True, bounds=bounds)\n",
    "            theta_opt.append(opt_res.x)\n",
    "            func_min.append(opt_res.fun)\n",
    "        best = np.argmin(func_min)\n",
    "        if verbose:\n",
    "            print(f'Nll minimum : {func_min[best]}, optimal hyperparameters : {np.exp(theta_opt[best])}')\n",
    "        self.kernel.theta = theta_opt[best][:-1]\n",
    "        self.noise = theta_opt[best][-1]\n",
    "        self._compute_K()\n",
    "\n",
    "    def sample_functions(self, X, n_functions : int = 1, plot : bool = True):\n",
    "        Ks = self.kernel(self._obs[0], X)\n",
    "        Kss = self.kernel(X)\n",
    "        Kinv = self._invert(self._K) \n",
    "        mean = Ks.T.dot(Kinv).dot(self._obs[1])\n",
    "        covariance = Kss - Ks.T.dot(Kinv).dot(Ks)\n",
    "\n",
    "        samples = np.random.multivariate_normal(mean, covariance, n_functions)\n",
    "        if plot and len(X.shape) < 2:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(self._obs[0], self._obs[1], marker=\"o\", s=50, c=\"C1\")\n",
    "            for i in range(samples.shape[0]):\n",
    "                ax.plot(X.squeeze(), samples[i, :], lw=1, ls='--')\n",
    "            #plt.savefig('samples_Wtrain_noise'+str(self._noise_sigma)+'.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        return samples\n",
    "\n",
    "    def predict(self, X : Coordinates, compute_std : bool = True, compute_covariance : bool = False):\n",
    "        assert not(compute_std and compute_covariance), 'choose at most one among std and covariance'\n",
    "        Ks = self.kernel(self._obs[0], X)\n",
    "        Kinv = self._invert(self._K) \n",
    "        mean = None   \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        if compute_covariance:\n",
    "            Kss = self.kernel(X)\n",
    "            cov = None \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            return mean + self._obs_scaler, cov\n",
    "\n",
    "        elif compute_std:\n",
    "            dummy = Kinv.dot(Ks)\n",
    "            var = np.diag(self.kernel(X)).copy()\n",
    "            var -= np.einsum(\"ji,ji->i\", Ks, dummy)\n",
    "            var[var<0] = 0 # there could be negative variances because of computational errors\n",
    "            return mean + self._obs_scaler, np.sqrt(var)\n",
    "        else:\n",
    "            return mean + self._obs_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeacfb2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "555fc98ecc0928d03d02c1abc51ea67c",
     "grade": true,
     "grade_id": "compute_K",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute_K - 1 point\n",
    "kernel = Matern52()\n",
    "gp = GP(kernel=kernel)\n",
    "test_framework = Frame(dim = 1, func = 'func_2')\n",
    "\n",
    "np.random.seed(12)\n",
    "observations = test_framework.get_samples(n_samples = 2)\n",
    "gp._compute_K(observations)\n",
    "answer = np.array([[1.01000000e+00, 1.47418222e-05],\n",
    "                   [1.47418222e-05, 1.01000000e+00]])\n",
    "assert np.isclose(gp._K, answer).all(), 'ooops...'\n",
    "\n",
    "# similar hidden test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817016a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7089b0d4dfacfd679321c3de3e7da855",
     "grade": true,
     "grade_id": "invert",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# invert - 1 point\n",
    "kernel = Matern52()\n",
    "gp = GP(kernel=kernel)\n",
    "\n",
    "K = np.array([[1, 1],\n",
    "              [1, 5]])\n",
    "Kinv = np.array([[ 1.25, -0.25],\n",
    "                 [-0.25,  0.25]])\n",
    "assert np.isclose(gp._invert(K), Kinv).all(), 'ooops...'\n",
    "\n",
    "# similar hidden test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6bc98f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "295b053b4ef06c8360d5e75f42d03943",
     "grade": true,
     "grade_id": "predict",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# predict - 1 point\n",
    "\n",
    "test_framework = Frame(dim = 1, func = 'func_2')\n",
    "kernel = Matern52()\n",
    "gp = GP(kernel=kernel)\n",
    "\n",
    "np.random.seed(12)\n",
    "observations = test_framework.get_samples(n_samples = 4)\n",
    "gp._compute_K(observations)\n",
    "val, cov = gp.predict(X=np.array([5, 6]), compute_covariance=True, compute_std=False)\n",
    "true_val = np.array([-1.6872044,  -0.10250491])\n",
    "true_cov = np.array([[ 0.23048763, -0.06465079],\n",
    "                     [-0.06465079,  0.6058542 ]])\n",
    "assert np.isclose(val, true_val).all() and np.isclose(cov, true_cov).all(), 'ooops...'\n",
    "\n",
    "# similar hidden test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d2cf2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b68b4a1f819bca17165e1f9bf5afba8c",
     "grade": false,
     "grade_id": "cell-e6e17befe4a23495",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's have a look at the effect of the kernel parameters on the GP.\n",
    "\n",
    "As stated above the length scale controls the horizontal scale over which the function changes. Given a set of observations let's see what the predictions of the GP will be varying the kernel parameters. \n",
    "\n",
    "(If you had problems implementing the SE kernel you can use Matern52 or Matern32 kernels from the utils file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09dfa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "\n",
    "test_framework = Frame(dim = 1, func = 'func_2')\n",
    "observations = test_framework.get_samples(n_samples = 10)\n",
    "upper_limit = test_framework.up\n",
    "lower_limit = test_framework.low\n",
    "length_scale_bounds = ((upper_limit - lower_limit)/10, upper_limit/2)\n",
    "\n",
    "print('Plotting the observations and the ground truth')\n",
    "test_framework.plot(samples = observations)\n",
    "for length_scale in [1, 0.5, 0.1]:\n",
    "    print('LENGTH SCALE = ', length_scale)\n",
    "    kernel = SE_isotropic(length_scale, length_scale_bounds) \n",
    "#     kernel = Matern52(length_scale, length_scale_bounds) \n",
    "    gp = GP(kernel=kernel)\n",
    "    gp._compute_K(observations)\n",
    "    X = np.linspace(lower_limit, upper_limit, 100)\n",
    "    print('\\t Plotting 3 sample functions from the GP posterior')\n",
    "    samples = gp.sample_functions(X, n_functions = 3)\n",
    "    print('\\t Plotting mean and 2*std confidence bounds of GP posterior')\n",
    "    test_framework.plot(surrogate = gp, samples = observations)\n",
    "    \n",
    "print(\"Finally let's try to fit our GP on the observed data\")\n",
    "print('First of the optimal parameters is the length scale, second is the observation noise')\n",
    "gp.fit(observations, verbose=True)\n",
    "test_framework.plot(surrogate = gp, samples = observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe58d4e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1da4fe221e8028c4300b9588f3c2b72d",
     "grade": false,
     "grade_id": "cell-521189f1af5221a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can notice from the plots, increasing the length scale the ensemble of functions represented by the GP gets smoother but the interpolation of observed data gets worse. Fitting the GP to the data means trying to balance the trade off between these two behaviours. \n",
    "\n",
    "This is a general problem in Machine Learning and is usually referred to as the <b>bias/variance</b> tradeoff. In our case a small length scale means high variance, a large length scale a large bias. A similar reasoning can be made for the $\\sigma_{y}$, think about it (and test if you are curious)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25fd1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1213dad6b821d98db975e01e0b2eaf8",
     "grade": false,
     "grade_id": "cell-8bea682488436ef5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have our probabilistic model, a.k.a. surrogate function, which represents our prior belief over the possible objective functions and we now want to refine this model by observing new data: after observing the output of each query of the objective, the prior is updated to produce a more informative posterior distribution over the space of objective functions.\n",
    "\n",
    "Then, how do we select where to observe the function next? \n",
    "\n",
    "The approach in Bayesian optimization is to design an acquisition function, which is typically an inexpensive function that \"measures\" how desirable evaluating $f(\\cdot)$ in $x$ is expected to be for the maximization problem and for refining our probabilistic model. In short, we are replacing our original optimization problem with another optimization problem, but on a much cheaper function.\n",
    "\n",
    "There are many acquisition functions that are currently used in BayesOpt. Just to name a few: upper confidence bound (UCB), probability of improvement (PI), expectation improvement (EI), Thompson sampling (TS), knowledge gradient (KG), entropy search (ES) and predictive entropy search (PES). \n",
    "\n",
    "We will try to figure out what kind of behaviour we would desire from our acquisition function using UCB as an example, then we will try to implement EI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee147586",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c92e7c04a57f50ac4618d353ceaf9f9",
     "grade": false,
     "grade_id": "cell-ec380790cdda729a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "But just before that, we have to make an aside. Among the various approaches we can take to find the maximum of the acquisition function we will opt for a simple method: we will sample random points in our design space $\\mathcal{X}$, compute the acquisition function in each point and select its maximum. Thus we need an efficient way to sample from the domain, where efficient means that we need to cover as much volume as possible in the least number of samples. More formally: we want our set of samples to be a low-discrepancy sequence. \n",
    "\n",
    "Simply sampling from a uniform distribution doesn't guarantee that the discrepancy will be low, but many methods are available. We will implement a simple method which is often used for Monte Carlo integration, the latin hypercube sampling.\n",
    "\n",
    "A Latin square is a square grid of the sample space $\\mathcal{S}$ containing one and only one sample in each row and each column, as shown in the following picture.\n",
    "<img src=\"LS.png\" alt=\"drawing\" width=\"150\"/>\n",
    "\n",
    "A Latin hypercube is its generalization when $|\\mathcal{S}| > 2$, whereby each sample is the only one in each axis-aligned hyperplane containing it. The procedure to get the samples is quite easy. For $N$ samples in a $D$-dimensional sample space: divide each dimension in N equal intervals, draw randomly a sample from each of the $N^{D}$ hypercubes.\n",
    "\n",
    "Try to implement LHS in the box below (you can implement it as you prefer, my comments are just a suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6f495",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cac8fbefce29c0f41cfa0b83abb59447",
     "grade": false,
     "grade_id": "LHS",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def latin_hypercube_sampler(dim : int, n_samples : int):\n",
    "    # build a grid, dividing each dimension in n_samples subintervals\n",
    "    # permute randomly dimension-wise\n",
    "    grid = None     # grid.shape = (n_samples, dim)\n",
    "    # sample n_samples*dim random offsets from a uniform distribution \n",
    "    offsets = None  # offsets.shape = grid.shape\n",
    "    # sum the offsets to the grid to produce our sequence of samples\n",
    "    samples = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return samples[:, np.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c444301",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3938c7e58ca5ee7afbefb6776c56d965",
     "grade": true,
     "grade_id": "sampler",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sampler - 1 point\n",
    "assert latin_hypercube_sampler(dim=2,n_samples=3).shape == (3,1,2)\n",
    "\n",
    "# hidden test to check if samples represent a latin hypercube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af3a3e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7712c0752a15cf2141ab41dc6befd818",
     "grade": false,
     "grade_id": "cell-ba48dde6a2fb4f13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's compare our LHS with uniformly drawn samples and Sobol sequences. Sobol sequences are quasi-random low-discrepancy sequences, a little tricky to implement but, as you will see running the code below, they converge very fastly to equidistribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8402d57",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34a920fb1f8dc919da7985d02102873a",
     "grade": false,
     "grade_id": "cell-d331a133d993e488",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "for n in [32, 64, 256]:\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, sharex='all', figsize=(15, 5))\n",
    "    lat_samples = latin_hypercube_sampler(dim=2,n_samples=n).squeeze()\n",
    "    unif_samples = np.random.rand(n, 2)\n",
    "    sob_samples = sobol_sampler(dim=2,n_samples=n).squeeze()\n",
    "    ax1.scatter(unif_samples[:,0], unif_samples[:,1])\n",
    "    ax1.set_title('Random Uniform')\n",
    "    ax2.scatter(lat_samples[:,0], lat_samples[:,1])\n",
    "    ax2.set_title('LHS')\n",
    "    ax3.scatter(sob_samples[:,0], sob_samples[:,1])\n",
    "    ax3.set_title('Sobol Sequence')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58faeea6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bef932ac74dfdafbb4386ee2d74382c5",
     "grade": false,
     "grade_id": "cell-53bd0650297b8dfd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can now turn back to the acquisition functions. \n",
    "\n",
    "Two straightforward ideas would be: \n",
    "1. be cautious -> query the objective function where our current model has the highest uncertainty;\n",
    "2. be greedy -> query the objective function at the maximum of our current model.\n",
    "\n",
    "The problem of deciding which of these two approaches to take is well known in reinforcement learning and it is usually referred to as the <b>exploration VS exploitation</b> problem. In the code below you can find a naive implementation of both methods. (Run the cell, we will need it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd99f9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d84bf6cb4921c6dd40a690e90d246978",
     "grade": false,
     "grade_id": "cell-955c81e354303c65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Cautious(AcquisitionFunc):\n",
    "    def __call__(self, X : Coordinates, model : Regressor, *args) -> float:\n",
    "        _, sigma = model.predict(X)\n",
    "        return sigma\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Cautious'\n",
    "\n",
    "    \n",
    "class Greedy(AcquisitionFunc):\n",
    "    def __call__(self, X : Coordinates, model : Regressor, *args) -> float:\n",
    "        mean = model.predict(X, compute_std = False)\n",
    "        return -mean # there is a minus here because what we actually want is to minimize our obj function\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Greedy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d536c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bade7d93107052a1eeb41aa90289313",
     "grade": false,
     "grade_id": "cell-726443aced7b0e38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We could try to be more flexible by maximizing a linear combination of the predicted value and the confidence in the prediction. To do so we simply introduce another parameter that we use to regulate the tradeoff between these two terms: we have just invented the Upper Confidence Bound acquisition function.\n",
    "\n",
    "Unfortunately other people thought about this before us, so no publication...\n",
    "(Remember to run the box below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb7a8e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b2899ce75eab7269cdb8619344132e3",
     "grade": false,
     "grade_id": "cell-5d04ede54026967b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Upper_Confidence_Bound(AcquisitionFunc):\n",
    "    def __init__(self, tradeoff : float = 1):\n",
    "        super().__init__()\n",
    "        self.tradeoff = tradeoff\n",
    "\n",
    "    def __call__(self, X : Coordinates, model : Regressor, *args) -> float:\n",
    "        mean, sigma = model.predict(X)\n",
    "        return - mean + self.tradeoff * sigma\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'UCB with tradeoff = {self.tradeoff}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7efaaa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e37234d1bfb92cf90e8014516646e278",
     "grade": false,
     "grade_id": "cell-9495d28f55e9cbf2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Running the code below we will test the behaviour of our acquisition functions: in blue we plot the acquisition function, the selected next point to query (maximum of acq. function) is plotted in the graph above in red. \n",
    "\n",
    "As you can notice the UCB generates a behaviour that is an intermediate between the completely explorative or completely exploitative approaches. Try to modify the tradoff parameter and see what happens.\n",
    "\n",
    "(If you had any problem implementing latin hypercube sampler (LHS) or SE kernel you can use Sobol sampler and Matern kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET FRAMEWORK\n",
    "np.random.seed(5)\n",
    "test_framework = Frame(dim = 1, func = 'func_1')\n",
    "observations = test_framework.get_samples(n_samples = 3)\n",
    "upper_limit = test_framework.up\n",
    "lower_limit = test_framework.low\n",
    "length_scale_bounds = ((upper_limit - lower_limit)/6, upper_limit/2)\n",
    "kernel = SE_isotropic(length_scale_bounds = length_scale_bounds)\n",
    "#kernel = Matern52(length_scale_bounds = length_scale_bounds)\n",
    "gp = GP(kernel=kernel)\n",
    "gp.fit(observations)\n",
    "\n",
    "# SET ACQUISITION FUNCTIONS AND SAMPLER\n",
    "cautious = Cautious() \n",
    "greedy = Greedy()\n",
    "ucb = Upper_Confidence_Bound(tradeoff=2)\n",
    "samples = latin_hypercube_sampler(dim=1, n_samples=32) \n",
    "# samples = sobol_sampler(dim=1, n_samples=32)\n",
    "\n",
    "# RUN\n",
    "for acquisition in [cautious, greedy, ucb]:\n",
    "    samples_scaled = []\n",
    "    acq_values = []\n",
    "    for sample in samples:\n",
    "        sample = sample * (upper_limit - lower_limit) + lower_limit\n",
    "        val = acquisition(sample, gp)\n",
    "        acq_values.append(val)\n",
    "        samples_scaled.append(sample)\n",
    "    best = np.argmax(acq_values)\n",
    "    print(f'acquisition function : {acquisition}')\n",
    "    test_framework.plot(surrogate = gp, samples = observations, \n",
    "                        acquisition = (samples_scaled, acq_values), \n",
    "                        minimum = (samples_scaled[best], gp.predict(samples_scaled[best], compute_std=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5392eba5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5b1eb1e82626e9094ae4007b6772a05",
     "grade": false,
     "grade_id": "cell-f1590a359766fc10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "UCB is easy to understand and implement but has a major drawback: the optimality of the tradeoff parameter is strongly problem dependent. We are trying to build a framework (BayesOpt) that will allow us to automatically optimize some parameters but in doing so we have introduced another free parameter that we have to tune.\n",
    "\n",
    "We will try now to implement a quite popular acquisition function that solves this problem: the Expected Improvement (EI).\n",
    "\n",
    "Assume $f'$ is the minimal value of $f$ observed so far, i.e. $f'= \\min_{i=1:N} f(x_{i})$. EI evaluates $f$ at the point that, in expectation, improves upon $f'$ the most, i.e. we want to maximize the expectation of the utility function $u(x) = \\max (0, f' - f(x))$. In formula:\n",
    "<br><center>$\\alpha_{EI}(x) = \\mathbb{E}[u(x)|\\mathcal{D}] = \\int_{-\\infty}^{f'} (f' - f)\\mathcal{N}(f; \\mu, \\sigma^{2}) \\,df$</center>\n",
    "<center>$= (f' - \\mu)\\Phi(f';\\mu.\\sigma^{2}) + \\sigma\\mathcal{N}(f';\\mu, \\sigma^{2})$</center>\n",
    "\n",
    "The first of these two terms can be interpreted as an exploitation term  while the second an exploration one and the trade off between these two is captured \"automatically\" by this criterion.\n",
    "\n",
    "Hints: take a look at norm.cdf and norm.pdf functios in scipy.stats ('norm' is already imported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45553570",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30e8f467d6e35e5c89f98580618e7890",
     "grade": false,
     "grade_id": "EI",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Expected_Improvement(AcquisitionFunc):\n",
    "    def __call__(self, X : Coordinates, model : Regressor, obs : Optional[Coordinates] = None) -> float:\n",
    "        if obs is not None:\n",
    "            actual_opt = np.min(model.predict(obs, compute_std = False)) \n",
    "        else:\n",
    "            actual_opt = 0\n",
    "        mean, sigma = model.predict(X)\n",
    "        sigma = sigma.reshape(-1,1)\n",
    "        \n",
    "        value = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c421a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19a6a14a2b6f487323ae0e2c4adceaeb",
     "grade": true,
     "grade_id": "acquisition",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# acquisition - 1 point\n",
    "np.random.seed(6)\n",
    "test_framework = Frame()\n",
    "observations = test_framework.get_samples(n_samples = 3)\n",
    "upper_limit = test_framework.up\n",
    "lower_limit = test_framework.low\n",
    "length_scale_bounds = ((upper_limit - lower_limit)/6, upper_limit/2)\n",
    "\n",
    "kernel = Matern52(length_scale_bounds = length_scale_bounds)\n",
    "gp = GP(kernel=kernel)\n",
    "gp.fit(observations)\n",
    "acquisition = Expected_Improvement()\n",
    "\n",
    "assert np.isclose(acquisition(np.array([2]), gp), 0.62150429), 'Error in EI implementation'\n",
    "\n",
    "# hidden test (another check on EI value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8689ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f94a8862088fed8b853e50ae8d4f9907",
     "grade": false,
     "grade_id": "cell-f6b01a585fa8e25d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have now everything we need for our Bayesian optimization framework, you can find the BayesOpt class in the utils file. \n",
    "\n",
    "We will test it first on our toy problems. \n",
    "<br>Try it out on different datasets (read comments next to uppercase variables).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8937c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(113)\n",
    "\n",
    "EPOCHS = 10\n",
    "DIM = 1 # or 2 (for 2 dimensions only with 'func_1' was implemented)\n",
    "FUNC = 'func_2' # or 'func_1', or 'func_3'\n",
    "\n",
    "# set framework\n",
    "test_framework = Frame(dim = DIM, func = FUNC)\n",
    "observations = test_framework.get_samples(n_samples = 1)\n",
    "upper_limit = test_framework.up\n",
    "lower_limit = test_framework.low\n",
    "length_scale_bounds = ((upper_limit - lower_limit)/EPOCHS, upper_limit/2)\n",
    "\n",
    "test_framework.plot(samples = observations)\n",
    "\n",
    "# set surrogate model\n",
    "# kernel = SE_isotropic(length_scale_bounds = length_scale_bounds)\n",
    "kernel = Matern52(length_scale_bounds = length_scale_bounds)\n",
    "gp = GP(kernel=kernel)\n",
    "\n",
    "# set acquisition funciton\n",
    "ei = Expected_Improvement()\n",
    "#ucb = Upper_Confidence_Bound(tradeoff = 2)\n",
    "\n",
    "# set BayesOpt and run \n",
    "optimizer = BayesOpt(function = test_framework, \n",
    "                     surrogate = gp, \n",
    "                     bounds = {'lower': lower_limit, 'upper': upper_limit}, \n",
    "                     acquisition = ei, #ucb \n",
    "                     sampler = latin_hypercube_sampler, #sobol_sampler,\n",
    "                     observations = observations, \n",
    "                     n_samples = 1024\n",
    "                    )\n",
    "\n",
    "opt_res = optimizer.run(epochs = EPOCHS, plot_steps = True)\n",
    "\n",
    "# print results\n",
    "print(f'optimal noise value :{np.exp(optimizer._surrogate.noise)}, optimal kernel parameters :{optimizer._surrogate.kernel.hyperparams}')\n",
    "\n",
    "print(f'minimum value : {opt_res[1]} found in position : {opt_res[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7980aa5b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ee68723b1a9cf795afea4d7a84ca616",
     "grade": false,
     "grade_id": "cell-44932a0d78c9da12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally we can use our GP-based BayesOpt implementation to tune some of the hyperparameters of the simple MLP you implemented for exercise 6 (check the 'Net' class in the utils file): \n",
    "1. the number of hidden units;\n",
    "2. the learning rate;\n",
    "3. the batch size.\n",
    "\n",
    "For each evaluation we are training the network for 5 epochs only (otherwise it would take a long time to run this) but you can notice how performance already improves a lot w.r.t. the results we had simply setting the hyperparameters to reasonable values (just as a reminder, in exercise 6 we scored 0.33 for the LUMO). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "test_framework = Net()\n",
    "observations = test_framework.get_samples(n_samples = 1)\n",
    "upper_limit = test_framework.up\n",
    "lower_limit = test_framework.low\n",
    "length_scale_bounds = ((upper_limit - lower_limit)/EPOCHS, upper_limit/2)\n",
    "\n",
    "kernel = SE_isotropic(length_scale_bounds = length_scale_bounds)\n",
    "#kernel = Matern52(length_scale_bounds = length_scale_bounds)\n",
    "\n",
    "gp = GP(kernel=kernel)\n",
    "\n",
    "ei = Expected_Improvement()\n",
    "#ucb = Upper_Confidence_Bound(tradeoff = 2)\n",
    "\n",
    "optimizer = BayesOpt(function = test_framework, \n",
    "                     surrogate = gp, \n",
    "                     bounds = {'lower': lower_limit, 'upper': upper_limit}, \n",
    "                     acquisition = ei, #ucb, \n",
    "                     sampler = latin_hypercube_sampler, #sobol_sampler,\n",
    "                     observations = observations, \n",
    "                     n_samples = 1024\n",
    "                    )\n",
    "opt_res = optimizer.run(epochs = EPOCHS)\n",
    "\n",
    "hp = test_framework._scale(opt_res[0])\n",
    "print(f'maximum r2_score : {-opt_res[1]} found for : {{ hidden units : {hp[0]}, lr : {np.round(hp[1], 4)}, batch size : {hp[2]} }}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75169c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
