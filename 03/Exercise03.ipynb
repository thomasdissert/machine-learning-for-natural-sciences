{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c0c48187059d204b887b5f08d91648b",
     "grade": false,
     "grade_id": "cell-8a7cd222d4950599",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise Sheet No. 3\n",
    "\n",
    "---\n",
    "\n",
    "> Machine Learning for Natural Sciences, Summer 2021, Jun.-Prof. Pascal Friederich, pascal.friederich@kit.edu\n",
    "> \n",
    "> Deadline: 09.05.2021, 8am\n",
    "\n",
    "---\n",
    "\n",
    "**Topic**: This exercise sheet will focus on linear algebra, precision, recall and feature reduction. You will continue to use ``numpy`` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8ffb30bf172b0c558a7d62470462174",
     "grade": false,
     "grade_id": "cell-c26ffc5de714a368",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.1 Distance function computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccbb0e442ec0d33e6b416949e7ea3a7a",
     "grade": false,
     "grade_id": "cell-4bf94758d89ed7fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For many feature descriptors and also for a specific implementation of the nearest neighbor classifier, the Euclidean mutual distance between a set of points must be computed. This serves as a measure on how two points are distinct or how far apart they are in Euclidean space. We will make use of this very often in the future. Therefore this exercise focus on an efficient implementation using numpy. You should gain a better unstanding of `numpy` methods.\n",
    "\n",
    "**3.1.1** Implement a function ``dist_loop(A,B)`` to computes the Euclidean distance between all instances between two sets of points $A \\subset \\mathbb{R}^{D}$ and $B \\subset \\mathbb{R}^{D}$. The input should be two matrices of shape $N \\times D$ and $M \\times D$. Do this by using explicit python loops to find the distance $d_{ij} = || a_{i} - b_{j} ||$ between two points $a_{i} \\in A$ and $b_{i} \\in B$. The output should be a $N \\times M$ distance matrix. For the calculation of the Euclidean distance you might want to use ``numpy.square()``, ``numpy.sum()`` and ``numpy.sqrt()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90e6ddbc23e3e3b9b41fbb33d6f9be05",
     "grade": false,
     "grade_id": "cell-c33edbe7e3ce1318",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import sys\n",
    "n = 500\n",
    "m = 1000\n",
    "d = 3\n",
    "A_data = np.reshape(random.rand(n*d),(n,d))\n",
    "B_data = np.reshape(random.rand(m*d),(m,d))\n",
    "print(\"A shape:\", A_data.shape, \"B shape:\", B_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8501f3bf68a844bf562dc6c0f94bb1d3",
     "grade": false,
     "grade_id": "dist_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dist_loop(A,B):\n",
    "    if A.shape[-1] != B.shape[-1]:\n",
    "        raise ValueError(\"Error A and B must have same last dimension but got\", A.shape[-1], B.shape[-1])\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0eb0a49c182bf0e5a637c7070d13d2bb",
     "grade": false,
     "grade_id": "cell-fa9a5e0893f92ee1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.1.2** Since loops are rather slow in python, and more efficient code is required for numeric operations, write another function ``dist_vec(A,B)`` to compute the distance relying\n",
    "on vectorization with ``numpy`` methods. Consult https://www.safaribooksonline.com/library/view/python-for-data/9781449323592/ch04.html and https://softwareengineering.stackexchange.com/questions/254475/how-do-i-move-away-from-the-for-loop-school-of-thought for information on how to do this. \n",
    "\n",
    "Tip: There is more than one way to do it. For the most straightforward answer, you need to add an additional dimension to `np.arrays` via, for example, `expand_dims`. If two `np.arrays` do not have matching shape they are then automatically broadcasted by repeating their respective element along the axis in question. Beside broadcasting, also the [indexing rules](https://numpy.org/doc/stable/reference/arrays.indexing.html) (required for 3.2, 3.3) of `numpy` help with vectorization to avoid pyhton loops. You must not use ``scipy`` or its methods for this task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c528a8f299889fc60698e8e2ca273aad",
     "grade": false,
     "grade_id": "dist_vec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dist_vec(A,B):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7df20b8c939c99028a2d58adbf4d0f6",
     "grade": false,
     "grade_id": "cell-fc0ec9c589763c8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check that the two function return the same result. And check the output shape of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4b043d946187d5d4b08030dc999dd25",
     "grade": false,
     "grade_id": "difference_dist",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "result_loop = dist_loop(A_data,B_data)\n",
    "result_vec = dist_vec(A_data,B_data)\n",
    "result_vec_shape = None # Check shape of result_loop\n",
    "result_loop_shape = None # Check shape of result_vec\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e12995c578ef850b181a8480d7efb5e4",
     "grade": false,
     "grade_id": "cell-b4c698e9d03d3613",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now compare the run times of the two implementations using jupyter's ``%timeit`` command or pythons ``time``. How much faster is the vectorized version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8564c31d4432b708f22d7e3c05fe86f7",
     "grade": false,
     "grade_id": "cell-86d6de253ac2af1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# measure time for loop\n",
    "%timeit result_loop = dist_loop(A_data,B_data)\n",
    "# measure time for loop\n",
    "%timeit result_vec = dist_vec(A_data,B_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b24b19b8a3cbe955f59b06db7827d968",
     "grade": false,
     "grade_id": "speed_up",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "speed_up_factor = 1 # A rough estimation is okay.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64d6dfd3de6acc0e4594434ae7059cdd",
     "grade": false,
     "grade_id": "cell-a20dc8356bb8b477",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note: It is absolutely critical that you understand vectorization, and with this the indexing and broadcasting methods of numpy. Not only do we need fast performance, but also all deep learning frameworks are based on array or tensor operations just like you used with ``numpy``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "199a7da406fe7b3c9659a4b52f53dc2e",
     "grade": true,
     "grade_id": "test_funs_1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert callable(dist_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05643463f89fd50e041bf163fdca4b47",
     "grade": true,
     "grade_id": "test_funs_2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(dist_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "839e15828e766b4554ff180df1e77b79",
     "grade": true,
     "grade_id": "test_loop_diff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert result_loop is not None\n",
    "assert result_vec is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c6c6b013eac1bb0f4bca02179c6d58e",
     "grade": true,
     "grade_id": "test_shape_dist",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert result_vec_shape is not None\n",
    "assert result_loop_shape is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a6e71ce926e10b1a242d37373052a61",
     "grade": true,
     "grade_id": "speed_up_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert speed_up_factor > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc2738648d5a0815497e45f7ae8687f8",
     "grade": false,
     "grade_id": "cell-cae27f50792e197e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.2 Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46ed7ff0f5905f367ba503ced12acd2a",
     "grade": false,
     "grade_id": "cell-9f173d428aa9d6b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, we use sklearn's digits dataset for an image retrieval experiment. Given any image\n",
    "from this dataset as a query, your algorithm shall find all similar images, where we define similarity\n",
    "by \"contains the same digit\". Of course, only the features (i.e. the pixel values of the images) may be\n",
    "used for similarity search. The known labels only serve for testing the quality of the search result. This approach measures how clustered the calsses are in a defined feature space (i.e. pixels). Start loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3787756192c94dfc87a00604209cfefc",
     "grade": false,
     "grade_id": "cell-4694919154d6a077",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read and prepare the digits data\n",
    "digits = load_digits()\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "# Show digits\n",
    "fig = plt.figure(figsize = (10,3))\n",
    "plt.gray()\n",
    "plt.subplot(1,3,1); plt.axis('off')\n",
    "plt.imshow(images[0])\n",
    "plt.subplot(1,3,2); plt.axis('off')\n",
    "plt.imshow(images[1])\n",
    "plt.subplot(1,3,3); plt.axis('off')\n",
    "plt.imshow(images[2])\n",
    "fig.tight_layout(); plt.show()\n",
    "print(target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "295d4672f11e8228d408f8a8087a2517",
     "grade": false,
     "grade_id": "cell-3a005da3224b0a6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Define dissimilarity by the Euclidean distance between pixel values:\n",
    "\n",
    "$d(X_i,X_{i'} ) = || X_i - X_{i'}||^2_2$\n",
    "\n",
    "To efficiently compute these distances, you should use vectorization from exercise 3.1. Let $D$\n",
    "be the full dissimilarity matrix, i.e. $D_{i i'} = d(X_i,X_{i'})$. An ``np.argsort()`` of row $D_i$ now gives the similarity ordering of all digits relative to query digit $X_i$. The response sets $S_{im}$ consist of the $m$ nearest instances to query $X_i$ (including $X_i$ itself), with $m$ running over all values from 1 to $N$.\n",
    "\n",
    "Note: If you didn't manage to solve 3.1 you can now use `scipy.spatial.distance.cdist`. But you do not get points for this solution in 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c836438f8b806803bfa0482f51ceade5",
     "grade": false,
     "grade_id": "sort_Sim",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dist_xx = None # Compute distance matrix from data (data = digits[\"data\"]), do not change the data here!\n",
    "resp_Sim = None # Sort matrix dist_xx along each row, so that you can extract response sets for any m (with resp_Sim[row_idx, :m]) \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82f43810701d893a53c24dfc5609dfa0",
     "grade": false,
     "grade_id": "cell-e875203b21c8141c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The positive class is defined by the instances having the same label as the query, i.e. $Y_{i'} = Y_i$, and\n",
    "$N_i = \\# \\{i' \\in 1,\\dots,N : Y_{i'} = Y_i \\}$ is the total number of positives. Each response set defines a pair ($\\text{precision}_{im}$; $\\text{recall}_{im}$) as:\n",
    "\n",
    "$\\text{precision}_{im} = \\frac{\\text{TP}_i(m)}{\\text{TP}_i(m) + \\text{FP}_i(m)}$,      $\\text{recall}_{im} = \\frac{\\text{TP}_i(m)}{N_i}$\n",
    "\n",
    "where $\\text{TP}_i(m) = \\# \\{i' \\in S_{im} : Y_i = Y_{i'}\\}$ and $\\text{FP}_i(m) = \\# \\{i' \\in S_{im} : Y_i \\neq Y_{i'}\\}$ are the number of true and false positives in $S_{im}$. Compute the $N\\times N$ precision matrix $P$ and recall matrix $R$ whose elements are the precision (respectively recall) values from these pairs, i.e. $P_{im} = \\text{precision}_{im}$ and $R_{im} = \\text{recall}_{im}$. \n",
    "\n",
    "Tip: You can use broadcasting with `np.expand_dims(axis)` and `np.cumsum` for vectorization. You may use indexing and indexing via boolean arrays, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9ed3362f91b34672a78a83856d87a2a",
     "grade": false,
     "grade_id": "true_false_positives",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "true_positives = None # as TP_i(m) of shape (1797, 1797)\n",
    "false_positives = None #  as FP_i(m) of shape (1797, 1797)\n",
    "total_positives = None # as N_i of shape (1797,)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Calculate the NxN precision and recall matrices\n",
    "Pim = None # of shape (1797, 1797)\n",
    "Rim = None # of shape (1797, 1797)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d0749f0dba43de25f4a7d357798a8e3",
     "grade": false,
     "grade_id": "cell-9449ea8b1fdb20db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For each digit class $k \\in \\{0,\\dots,9\\}$, compute $\\bar{P}_k$ and $\\bar{R}_k$ as the average of the rows of $P$ and $R$ referring to class $k$, i.e. where $Y_i = k$, with $m$ as the the free parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30f61b2e6026e40fc9a0081b52ad1bb5",
     "grade": false,
     "grade_id": "avg_PR",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Pk_m = None # averaged Pim of shape (10,1797)\n",
    "Rk_m = None # averaged Rim of shape (10,1797)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f3be12e6bbea5a00cb6f3a904a92507",
     "grade": false,
     "grade_id": "cell-f53c895913e8e3bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot the resulting precision/recall curves (using $m$ as the free parameter) and determine the area-under-curve (AUC) for each $k$. Do not use the implementation of ``sklearn`` in this task. This means you have to plot Recall vs. Precision for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b67dd0082177fd4ebf47f5d275c7a3c5",
     "grade": false,
     "grade_id": "AUC",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def auc_precision_recall(precision,recall):\n",
    "    # precision is P(m) for a specific class of shape (1797,)\n",
    "    # recall is R(m) for a specific class of shape (1797,)\n",
    "    return np.abs(np.trapz(y=precision, x=(recall)))\n",
    "# Get Area under curve with auc_precision_recall()\n",
    "AUC = None # List of AUC for each number 0,...,9 via auc_precision_recall()\n",
    "\n",
    "# Plot the Precision-Recall Curves\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75878f9a084127bda8a2fd0f32655406",
     "grade": true,
     "grade_id": "test_dist_digit_1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert dist_xx is not None\n",
    "assert dist_xx.shape[0] == 1797 and dist_xx.shape[1] == 1797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a0ae3fba6603ccff3efa85ecd69d5c8",
     "grade": true,
     "grade_id": "test_dist_digit_2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert resp_Sim is not None\n",
    "try:\n",
    "    assert np.all(resp_Sim[0:2,0:2] == np.array([[0,877],[1,93]]))\n",
    "except:\n",
    "    print(\"resp_Sim should contain indices that give a similarity ordering, please do not shuffle the data for grading tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83bf2a4fd870c95a76048808931b76ec",
     "grade": true,
     "grade_id": "test_po_neg_true",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert true_positives is not None\n",
    "try:\n",
    "    assert true_positives[0,0] == 1 and true_positives[0,-1] == 178\n",
    "except:\n",
    "    print(\"As a sanity test, the first entry should be always 1 and the lasts equals the number of class labels for that digit.\")\n",
    "    print(\"Number of 0's:\", np.sum(target == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d3fb47627be2304f01f0213d6a4df65",
     "grade": true,
     "grade_id": "test_po_neg_false",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert false_positives is not None\n",
    "try:\n",
    "    assert false_positives[0,0] == 0 and false_positives[0,-1] == 1619\n",
    "except:\n",
    "    print(\"As a sanity test, the first entry should be always 0 and the last equals the number of other class labels for that digit.\")\n",
    "    print(\"Number of classes;\",len(target) ,\"number of 0's:\", np.sum(target == 0), \"means: \", len(target) - np.sum(target == 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4961158916c2621ba8e8578003e61fa",
     "grade": true,
     "grade_id": "test_po_neg_total",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert total_positives is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e06372c5ee73eb652e8dd71c0c16c60",
     "grade": true,
     "grade_id": "test_Pim",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert Pim is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53184c0b34ee202559d937319b5c9b22",
     "grade": true,
     "grade_id": "test_Rim",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert Rim is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fb53df3951409ef80dfd7c6e5660c2d",
     "grade": true,
     "grade_id": "test_Pk",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert Pk_m is not None\n",
    "try:\n",
    "    assert Pk_m[0,0] - 1 < 0.01 and Pk_m[0,-1] - 0.09905 < 0.01\n",
    "except:\n",
    "    print(\"For closest neighbours we expect high precision, and low precision for all neighbours considered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b96828d807bf22e44cc6412293c0995",
     "grade": true,
     "grade_id": "test_Rk",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert Rk_m is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df0c85703d1f29ac9ae8b40314d68093",
     "grade": true,
     "grade_id": "test_auc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert AUC is not None\n",
    "try:\n",
    "    assert (AUC[0] - 0.9450) < 0.1 and (AUC[-1] - 0.4825) < 0.1\n",
    "except:\n",
    "    print(\"We expect a bad AUC for similar digits like 9,8,6. Interestingly '0' is well clustered with AUC of ca. 0.95\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "860f7fe87d5cc9b1dc74b2742c909889",
     "grade": false,
     "grade_id": "cell-69e2c302f41a7a78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3 PCA and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c04e414f1af3eef4d714bfa60f5f1bed",
     "grade": false,
     "grade_id": "cell-e295194e814491ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will try to reduce the number of features or pixels to two and re-test the precision/recall curves from exercise 3.2.\n",
    "\n",
    "As a first approach we try an unsupervised reduction of features, namely via Principle Component Analysis (PCA). The task is to use `scikit-learn`'s implementation of the PCA to reduce the number of pixels to two and then to make a scatter plot of the new features, where the color of each point represents the digits number.  Which property should this scatterplot have in order for the new features to be especially suitable for similarity search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b338b8dfadeacab31b4eda91cbe63f3",
     "grade": false,
     "grade_id": "PCA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "new_features_pca = None # Make new features of shape (1797, 2)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment from above for new features but this time with a supervised feature reduction. We use the Linear Discriminant Analysis (LDA), which is linear too but seeks to fit class conditional densities to the data and using Bayes’ rule. You can use the `scikit-learn`'s implementation of LDA. Repeat the step above and make a scatter plot of the new features, where the color of each point represents the digits number. What is the difference? Which method is better suited for dissimilarity search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66f378703c5300d21acf4de223af5684",
     "grade": false,
     "grade_id": "LDA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "new_features_lda = None # Make new features of shape (1797, 2)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat steps of 3.2. To do so, simply wrap the solution of 3.2 in a function as indicated below.\n",
    "\n",
    "Note: If you didn't solve 3.2, you can still give an answer, based on the scatter plots above, to the question in the last cell. The function below and the PCA/LDA recall-precision curve plots are not graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "325faa9e49cff32fe96ac4640c99782e",
     "grade": true,
     "grade_id": "cell-ffb452aa6e6575b6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def make_precision_recall_distance(data,target):\n",
    "    Pk_m, Rk_m = None, None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return Pk_m, Rk_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can plot the precision-recall curves for the dissimilarity by the Euclidean distance of the new features for the PCA and LDA.\n",
    "\n",
    "What do you observe? Does it improve with respect to the full digits? (manually set linear_reduction_answer to True or False to answer the question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84811c83cabe903d08fe67fbc94210bb",
     "grade": false,
     "grade_id": "improve",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "linear_reduction_answer = None # Get better: True , get worse: False\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16490a4e0c864de553629cf260b2620a",
     "grade": true,
     "grade_id": "test_PCA",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert new_features_pca is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6884306a40acfd4731817ed23ff0f92b",
     "grade": true,
     "grade_id": "test_LDA",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert new_features_lda is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbe21e0295309ec07515d39501befca5",
     "grade": true,
     "grade_id": "test_PCA_LDA_Recall",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert isinstance(linear_reduction_answer,bool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
